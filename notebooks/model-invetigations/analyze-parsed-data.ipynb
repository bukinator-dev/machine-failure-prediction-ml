{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d11190ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataframe with 390263 rows and 25 columns\n",
      "Time                  float64\n",
      "Demand 1              float64\n",
      "Control 1             float64\n",
      "Output Drive 1        float64\n",
      "Channel 1             float64\n",
      "Channel 2             float64\n",
      "Channel 3             float64\n",
      "Channel 4             float64\n",
      "Channel 1 Kurtosis    float64\n",
      "Channel 2 Kurtosis    float64\n",
      "Channel 3 Kurtosis    float64\n",
      "Channel 4 Kurtosis    float64\n",
      "Rear Input 1            int64\n",
      "Rear Input 2            int64\n",
      "Rear Input 3            int64\n",
      "Rear Input 4            int64\n",
      "Rear Input 5            int64\n",
      "Rear Input 6            int64\n",
      "Rear Input 7            int64\n",
      "Rear Input 8            int64\n",
      "condition              object\n",
      "rpm                     int64\n",
      "humidity                int64\n",
      "temperature             int64\n",
      "source_file            object\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Demand 1</th>\n",
       "      <th>Control 1</th>\n",
       "      <th>Output Drive 1</th>\n",
       "      <th>Channel 1</th>\n",
       "      <th>Channel 2</th>\n",
       "      <th>Channel 3</th>\n",
       "      <th>Channel 4</th>\n",
       "      <th>Channel 1 Kurtosis</th>\n",
       "      <th>Channel 2 Kurtosis</th>\n",
       "      <th>...</th>\n",
       "      <th>Rear Input 4</th>\n",
       "      <th>Rear Input 5</th>\n",
       "      <th>Rear Input 6</th>\n",
       "      <th>Rear Input 7</th>\n",
       "      <th>Rear Input 8</th>\n",
       "      <th>condition</th>\n",
       "      <th>rpm</th>\n",
       "      <th>humidity</th>\n",
       "      <th>temperature</th>\n",
       "      <th>source_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.176033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.209182</td>\n",
       "      <td>0.145823</td>\n",
       "      <td>1.624200e-15</td>\n",
       "      <td>2.52457</td>\n",
       "      <td>2.94874</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>faulty</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>1st at -10 2022Jun04-2239-0005.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001450</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.176033</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211458</td>\n",
       "      <td>0.209182</td>\n",
       "      <td>0.145823</td>\n",
       "      <td>1.624200e-15</td>\n",
       "      <td>2.52457</td>\n",
       "      <td>2.94874</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>faulty</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>1st at -10 2022Jun04-2239-0005.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006283</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.176033</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.206329</td>\n",
       "      <td>0.206513</td>\n",
       "      <td>0.150478</td>\n",
       "      <td>1.643320e-15</td>\n",
       "      <td>2.32290</td>\n",
       "      <td>2.46553</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>faulty</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>1st at -10 2022Jun04-2239-0005.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.009633</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.172626</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.206351</td>\n",
       "      <td>0.194663</td>\n",
       "      <td>0.148313</td>\n",
       "      <td>1.528270e-15</td>\n",
       "      <td>2.26458</td>\n",
       "      <td>2.55488</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>faulty</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>1st at -10 2022Jun04-2239-0005.csv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.013200</td>\n",
       "      <td>0.125011</td>\n",
       "      <td>0.172626</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.214463</td>\n",
       "      <td>0.214489</td>\n",
       "      <td>0.155652</td>\n",
       "      <td>1.791370e-15</td>\n",
       "      <td>2.53380</td>\n",
       "      <td>2.66379</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>faulty</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>-10</td>\n",
       "      <td>1st at -10 2022Jun04-2239-0005.csv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Time  Demand 1  Control 1  Output Drive 1  Channel 1  Channel 2  \\\n",
       "0  0.001450  0.125011   0.176033        0.000000   0.211458   0.209182   \n",
       "1  0.001450  0.125011   0.176033        0.000000   0.211458   0.209182   \n",
       "2  0.006283  0.125011   0.176033        0.000012   0.206329   0.206513   \n",
       "3  0.009633  0.125011   0.172626        0.000013   0.206351   0.194663   \n",
       "4  0.013200  0.125011   0.172626        0.000014   0.214463   0.214489   \n",
       "\n",
       "   Channel 3     Channel 4  Channel 1 Kurtosis  Channel 2 Kurtosis  ...  \\\n",
       "0   0.145823  1.624200e-15             2.52457             2.94874  ...   \n",
       "1   0.145823  1.624200e-15             2.52457             2.94874  ...   \n",
       "2   0.150478  1.643320e-15             2.32290             2.46553  ...   \n",
       "3   0.148313  1.528270e-15             2.26458             2.55488  ...   \n",
       "4   0.155652  1.791370e-15             2.53380             2.66379  ...   \n",
       "\n",
       "   Rear Input 4  Rear Input 5  Rear Input 6  Rear Input 7  Rear Input 8  \\\n",
       "0             0             0             0             0             0   \n",
       "1             0             0             0             0             0   \n",
       "2             0             0             0             0             0   \n",
       "3             0             0             0             0             0   \n",
       "4             0             0             0             0             0   \n",
       "\n",
       "   condition   rpm  humidity  temperature                         source_file  \n",
       "0     faulty  1000         0          -10  1st at -10 2022Jun04-2239-0005.csv  \n",
       "1     faulty  1000         0          -10  1st at -10 2022Jun04-2239-0005.csv  \n",
       "2     faulty  1000         0          -10  1st at -10 2022Jun04-2239-0005.csv  \n",
       "3     faulty  1000         0          -10  1st at -10 2022Jun04-2239-0005.csv  \n",
       "4     faulty  1000         0          -10  1st at -10 2022Jun04-2239-0005.csv  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load dataset (expects vibrations_data.csv in the notebook working directory)\n",
    "df = pd.read_csv(\"../../data/vibrations_data.csv\")\n",
    "\n",
    "print(f\"Loaded dataframe with {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "print(df.dtypes)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f258268d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, balanced_accuracy_score, f1_score, \n",
    "    roc_auc_score, precision_score, recall_score,\n",
    "    classification_report, confusion_matrix\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def analyze_and_train_best_model(\n",
    "    df, \n",
    "    target_col='condition',\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    exclude_cols=None,\n",
    "    metric='balanced_accuracy',\n",
    "    verbose=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Analyze dataset, split into train/test, train multiple ML models, and select the best one.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pandas.DataFrame\n",
    "        Input dataframe with features and target column\n",
    "    target_col : str, default='condition'\n",
    "        Name of the target column\n",
    "    test_size : float, default=0.2\n",
    "        Proportion of dataset to use for testing\n",
    "    random_state : int, default=42\n",
    "        Random seed for reproducibility\n",
    "    exclude_cols : list, default=None\n",
    "        List of column names to exclude from features (e.g., ['source_file', 'Time'])\n",
    "    metric : str, default='balanced_accuracy'\n",
    "        Metric to use for selecting best model ('balanced_accuracy', 'f1', 'roc_auc', 'accuracy')\n",
    "    verbose : bool, default=True\n",
    "        Whether to print detailed results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict : Dictionary containing:\n",
    "        - 'best_model': The best trained model\n",
    "        - 'best_model_name': Name of the best model\n",
    "        - 'scaler': Fitted StandardScaler\n",
    "        - 'label_encoder': Fitted LabelEncoder\n",
    "        - 'feature_cols': List of feature column names used\n",
    "        - 'results': Dictionary with all model results\n",
    "        - 'X_test': Test features\n",
    "        - 'y_test': Test labels\n",
    "        - 'X_train': Train features\n",
    "        - 'y_train': Train labels\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Data analysis\n",
    "    if verbose:\n",
    "        print(\"=\" * 60)\n",
    "        print(\"DATASET ANALYSIS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"Dataset shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "        print(f\"\\nTarget variable '{target_col}' distribution:\")\n",
    "        print(df[target_col].value_counts())\n",
    "        print(f\"\\nTarget variable '{target_col}' distribution (%):\")\n",
    "        print(df[target_col].value_counts(normalize=True) * 100)\n",
    "        print(f\"\\nMissing values:\")\n",
    "        print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "        if df.isnull().sum().sum() == 0:\n",
    "            print(\"No missing values found.\")\n",
    "    \n",
    "    # 2. Feature selection\n",
    "    if exclude_cols is None:\n",
    "        exclude_cols = ['source_file', 'Time']  # Default exclusions\n",
    "    \n",
    "    # Get numeric columns (excluding target and excluded columns)\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    feature_cols = [c for c in numeric_cols if c not in [target_col] + exclude_cols]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nSelected {len(feature_cols)} features: {feature_cols[:5]}...\" if len(feature_cols) > 5 else f\"\\nSelected {len(feature_cols)} features: {feature_cols}\")\n",
    "    \n",
    "    # 3. Prepare features and target\n",
    "    X = df[feature_cols].values\n",
    "    y_raw = df[target_col].values\n",
    "    \n",
    "    # Encode target labels\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y_raw)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nLabel encoding: {dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_)))}\")\n",
    "    \n",
    "    # 4. Train/test split (stratified to maintain class distribution)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, \n",
    "        test_size=test_size, \n",
    "        stratify=y, \n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nTrain set: {X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {X_test.shape[0]} samples\")\n",
    "        print(f\"Train class distribution: {np.bincount(y_train)}\")\n",
    "        print(f\"Test class distribution: {np.bincount(y_test)}\")\n",
    "    \n",
    "    # 5. Feature scaling\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # 6. Define models to test\n",
    "    models = {\n",
    "        \"Logistic Regression\": LogisticRegression(\n",
    "            max_iter=1000, \n",
    "            random_state=random_state,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"Random Forest\": RandomForestClassifier(\n",
    "            n_estimators=200, \n",
    "            random_state=random_state, \n",
    "            n_jobs=-1,\n",
    "            max_depth=20\n",
    "        ),\n",
    "        \"Gradient Boosting\": GradientBoostingClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=random_state,\n",
    "            max_depth=5\n",
    "        ),\n",
    "        \"AdaBoost\": AdaBoostClassifier(\n",
    "            n_estimators=100,\n",
    "            random_state=random_state\n",
    "        ),\n",
    "        \"SVM (RBF)\": SVC(\n",
    "            probability=True, \n",
    "            random_state=random_state,\n",
    "            kernel='rbf'\n",
    "        ),\n",
    "        \"K-Nearest Neighbors\": KNeighborsClassifier(\n",
    "            n_neighbors=5,\n",
    "            n_jobs=-1\n",
    "        ),\n",
    "        \"Decision Tree\": DecisionTreeClassifier(\n",
    "            random_state=random_state,\n",
    "            max_depth=15\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    # 7. Train and evaluate all models\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"TRAINING MODELS\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    results = {}\n",
    "    \n",
    "    for name, model in models.items():\n",
    "        if verbose:\n",
    "            print(f\"\\nTraining {name}...\")\n",
    "        \n",
    "        try:\n",
    "            # Train model\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            y_proba = None\n",
    "            if hasattr(model, \"predict_proba\"):\n",
    "                y_proba = model.predict_proba(X_test_scaled)[:, 1]\n",
    "            \n",
    "            # Calculate metrics\n",
    "            acc = accuracy_score(y_test, y_pred)\n",
    "            bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "            f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "            prec = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            rec = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "            \n",
    "            roc_auc = None\n",
    "            if y_proba is not None:\n",
    "                try:\n",
    "                    roc_auc = roc_auc_score(y_test, y_proba)\n",
    "                except:\n",
    "                    roc_auc = None\n",
    "            \n",
    "            results[name] = {\n",
    "                'model': model,\n",
    "                'accuracy': acc,\n",
    "                'balanced_accuracy': bal_acc,\n",
    "                'f1_score': f1,\n",
    "                'precision': prec,\n",
    "                'recall': rec,\n",
    "                'roc_auc': roc_auc,\n",
    "                'predictions': y_pred,\n",
    "                'probabilities': y_proba\n",
    "            }\n",
    "            \n",
    "            if verbose:\n",
    "                print(f\"  Accuracy: {acc:.4f}\")\n",
    "                print(f\"  Balanced Accuracy: {bal_acc:.4f}\")\n",
    "                print(f\"  F1 Score: {f1:.4f}\")\n",
    "                if roc_auc is not None:\n",
    "                    print(f\"  ROC-AUC: {roc_auc:.4f}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            if verbose:\n",
    "                print(f\"  Error training {name}: {str(e)}\")\n",
    "            results[name] = {'error': str(e)}\n",
    "    \n",
    "    # 8. Select best model based on specified metric\n",
    "    valid_results = {k: v for k, v in results.items() if 'error' not in v}\n",
    "    \n",
    "    if metric not in ['balanced_accuracy', 'f1_score', 'roc_auc', 'accuracy']:\n",
    "        metric = 'balanced_accuracy'\n",
    "        if verbose:\n",
    "            print(f\"\\nWarning: Invalid metric '{metric}'. Using 'balanced_accuracy' instead.\")\n",
    "    \n",
    "    # Handle ROC-AUC which might be None\n",
    "    if metric == 'roc_auc':\n",
    "        valid_results = {k: v for k, v in valid_results.items() if v.get('roc_auc') is not None}\n",
    "        if not valid_results:\n",
    "            metric = 'balanced_accuracy'\n",
    "            if verbose:\n",
    "                print(\"Warning: No models with ROC-AUC available. Using 'balanced_accuracy' instead.\")\n",
    "    \n",
    "    best_model_name = max(valid_results.keys(), key=lambda k: valid_results[k][metric])\n",
    "    best_model_info = valid_results[best_model_name]\n",
    "    \n",
    "    # 9. Print results summary\n",
    "    if verbose:\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(\"MODEL COMPARISON RESULTS\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\n{'Model':<25} {'Accuracy':<10} {'Bal Acc':<10} {'F1':<10} {'ROC-AUC':<10}\")\n",
    "        print(\"-\" * 65)\n",
    "        \n",
    "        sorted_results = sorted(\n",
    "            valid_results.items(), \n",
    "            key=lambda kv: kv[1][metric], \n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        for name, res in sorted_results:\n",
    "            roc_str = f\"{res['roc_auc']:.4f}\" if res['roc_auc'] is not None else \"N/A\"\n",
    "            print(f\"{name:<25} {res['accuracy']:<10.4f} {res['balanced_accuracy']:<10.4f} \"\n",
    "                  f\"{res['f1_score']:<10.4f} {roc_str:<10}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"BEST MODEL: {best_model_name} (based on {metric})\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"  Accuracy: {best_model_info['accuracy']:.4f}\")\n",
    "        print(f\"  Balanced Accuracy: {best_model_info['balanced_accuracy']:.4f}\")\n",
    "        print(f\"  F1 Score: {best_model_info['f1_score']:.4f}\")\n",
    "        if best_model_info['roc_auc'] is not None:\n",
    "            print(f\"  ROC-AUC: {best_model_info['roc_auc']:.4f}\")\n",
    "        \n",
    "        # Classification report for best model\n",
    "        print(f\"\\nClassification Report for {best_model_name}:\")\n",
    "        print(classification_report(y_test, best_model_info['predictions'], \n",
    "                                   target_names=label_encoder.classes_))\n",
    "        \n",
    "        # Confusion matrix\n",
    "        print(f\"\\nConfusion Matrix for {best_model_name}:\")\n",
    "        cm = confusion_matrix(y_test, best_model_info['predictions'])\n",
    "        print(cm)\n",
    "    \n",
    "    # 10. Retrain best model on full training data (optional, but good practice)\n",
    "    best_model = best_model_info['model']\n",
    "    # Create a fresh instance to retrain\n",
    "    best_model_class = type(best_model)\n",
    "    if best_model_name == \"Logistic Regression\":\n",
    "        final_model = LogisticRegression(max_iter=1000, random_state=random_state, n_jobs=-1)\n",
    "    elif best_model_name == \"Random Forest\":\n",
    "        final_model = RandomForestClassifier(n_estimators=200, random_state=random_state, n_jobs=-1, max_depth=20)\n",
    "    elif best_model_name == \"Gradient Boosting\":\n",
    "        final_model = GradientBoostingClassifier(n_estimators=100, random_state=random_state, max_depth=5)\n",
    "    elif best_model_name == \"AdaBoost\":\n",
    "        final_model = AdaBoostClassifier(n_estimators=100, random_state=random_state)\n",
    "    elif best_model_name == \"SVM (RBF)\":\n",
    "        final_model = SVC(probability=True, random_state=random_state, kernel='rbf')\n",
    "    elif best_model_name == \"K-Nearest Neighbors\":\n",
    "        final_model = KNeighborsClassifier(n_neighbors=5, n_jobs=-1)\n",
    "    elif best_model_name == \"Decision Tree\":\n",
    "        final_model = DecisionTreeClassifier(random_state=random_state, max_depth=15)\n",
    "    else:\n",
    "        final_model = best_model\n",
    "    \n",
    "    final_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    return {\n",
    "        'best_model': final_model,\n",
    "        'best_model_name': best_model_name,\n",
    "        'scaler': scaler,\n",
    "        'label_encoder': label_encoder,\n",
    "        'feature_cols': feature_cols,\n",
    "        'results': results,\n",
    "        'X_test': X_test,\n",
    "        'y_test': y_test,\n",
    "        'X_train': X_train,\n",
    "        'y_train': y_train,\n",
    "        'X_test_scaled': X_test_scaled,\n",
    "        'X_train_scaled': X_train_scaled\n",
    "    }\n",
    "\n",
    "# Example usage:\n",
    "# results = analyze_and_train_best_model(df, target_col='condition', test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3872ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DATASET ANALYSIS\n",
      "============================================================\n",
      "Dataset shape: 390263 rows, 25 columns\n",
      "\n",
      "Target variable 'condition' distribution:\n",
      "condition\n",
      "faulty     209662\n",
      "healthy    180601\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target variable 'condition' distribution (%):\n",
      "condition\n",
      "faulty     53.723258\n",
      "healthy    46.276742\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Missing values:\n",
      "Series([], dtype: int64)\n",
      "No missing values found.\n",
      "\n",
      "Selected 22 features: ['Demand 1', 'Control 1', 'Output Drive 1', 'Channel 1', 'Channel 2']...\n",
      "\n",
      "Label encoding: {'faulty': 0, 'healthy': 1}\n",
      "\n",
      "Train set: 312210 samples\n",
      "Test set: 78053 samples\n",
      "Train class distribution: [167729 144481]\n",
      "Test class distribution: [41933 36120]\n",
      "\n",
      "============================================================\n",
      "TRAINING MODELS\n",
      "============================================================\n",
      "\n",
      "Training Logistic Regression...\n",
      "  Accuracy: 0.8942\n",
      "  Balanced Accuracy: 0.8933\n",
      "  F1 Score: 0.8942\n",
      "  ROC-AUC: 0.9432\n",
      "\n",
      "Training Random Forest...\n",
      "  Accuracy: 1.0000\n",
      "  Balanced Accuracy: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "  ROC-AUC: 1.0000\n",
      "\n",
      "Training Gradient Boosting...\n",
      "  Accuracy: 0.9952\n",
      "  Balanced Accuracy: 0.9950\n",
      "  F1 Score: 0.9952\n",
      "  ROC-AUC: 0.9999\n",
      "\n",
      "Training AdaBoost...\n",
      "  Accuracy: 0.9378\n",
      "  Balanced Accuracy: 0.9372\n",
      "  F1 Score: 0.9378\n",
      "  ROC-AUC: 0.9874\n",
      "\n",
      "Training SVM (RBF)...\n",
      "  Accuracy: 0.9909\n",
      "  Balanced Accuracy: 0.9905\n",
      "  F1 Score: 0.9909\n",
      "  ROC-AUC: 0.9978\n",
      "\n",
      "Training K-Nearest Neighbors...\n",
      "  Accuracy: 0.9952\n",
      "  Balanced Accuracy: 0.9951\n",
      "  F1 Score: 0.9952\n",
      "  ROC-AUC: 0.9990\n",
      "\n",
      "Training Decision Tree...\n",
      "  Accuracy: 0.9986\n",
      "  Balanced Accuracy: 0.9986\n",
      "  F1 Score: 0.9986\n",
      "  ROC-AUC: 0.9994\n",
      "\n",
      "============================================================\n",
      "MODEL COMPARISON RESULTS\n",
      "============================================================\n",
      "\n",
      "Model                     Accuracy   Bal Acc    F1         ROC-AUC   \n",
      "-----------------------------------------------------------------\n",
      "Random Forest             1.0000     1.0000     1.0000     1.0000    \n",
      "Decision Tree             0.9986     0.9986     0.9986     0.9994    \n",
      "K-Nearest Neighbors       0.9952     0.9951     0.9952     0.9990    \n",
      "Gradient Boosting         0.9952     0.9950     0.9952     0.9999    \n",
      "SVM (RBF)                 0.9909     0.9905     0.9909     0.9978    \n",
      "AdaBoost                  0.9378     0.9372     0.9378     0.9874    \n",
      "Logistic Regression       0.8942     0.8933     0.8942     0.9432    \n",
      "\n",
      "============================================================\n",
      "BEST MODEL: Random Forest (based on balanced_accuracy)\n",
      "============================================================\n",
      "  Accuracy: 1.0000\n",
      "  Balanced Accuracy: 1.0000\n",
      "  F1 Score: 1.0000\n",
      "  ROC-AUC: 1.0000\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      faulty       1.00      1.00      1.00     41933\n",
      "     healthy       1.00      1.00      1.00     36120\n",
      "\n",
      "    accuracy                           1.00     78053\n",
      "   macro avg       1.00      1.00      1.00     78053\n",
      "weighted avg       1.00      1.00      1.00     78053\n",
      "\n",
      "\n",
      "Confusion Matrix for Random Forest:\n",
      "[[41931     2]\n",
      " [    0 36120]]\n",
      "\n",
      "============================================================\n",
      "FUNCTION OUTPUT SUMMARY\n",
      "============================================================\n",
      "Best Model: Random Forest\n",
      "Number of features used: 22\n",
      "Feature columns: ['Demand 1', 'Control 1', 'Output Drive 1', 'Channel 1', 'Channel 2', 'Channel 3', 'Channel 4', 'Channel 1 Kurtosis', 'Channel 2 Kurtosis', 'Channel 3 Kurtosis', 'Channel 4 Kurtosis', 'Rear Input 1', 'Rear Input 2', 'Rear Input 3', 'Rear Input 4', 'Rear Input 5', 'Rear Input 6', 'Rear Input 7', 'Rear Input 8', 'rpm', 'humidity', 'temperature']\n"
     ]
    }
   ],
   "source": [
    "# Use the function to analyze the dataset and train the best model\n",
    "model_results = analyze_and_train_best_model(\n",
    "    df, \n",
    "    target_col='condition',\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    exclude_cols=['source_file', 'Time'],  # Exclude non-feature columns\n",
    "    metric='balanced_accuracy',  # Metric to use for selecting best model\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Access the results\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"FUNCTION OUTPUT SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Best Model: {model_results['best_model_name']}\")\n",
    "print(f\"Number of features used: {len(model_results['feature_cols'])}\")\n",
    "print(f\"Feature columns: {model_results['feature_cols']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
